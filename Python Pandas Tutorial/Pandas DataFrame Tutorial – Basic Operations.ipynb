{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9881762a-b901-4e4f-b22d-e1a26a1ba11f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Pandas DataFrame Tutorial – Basic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98fc391e-cc16-49d6-8086-0cc07a2897b1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a21d62a-a4db-4e98-a5fb-305adfe52b82",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create DataFrame with None/Null to work with examples\n",
    "\n",
    "technologies =({\n",
    "    'Courses':[\"Spark\", \"PySpark\", \"Hadoop\", \"Python\", \"Pandas\", None, \"Spark\", \"Python\"],\n",
    "    'Fee':[22000, 25000, 23000, 24000, np.nan, 25000, 25000, 22000],\n",
    "    'Duration':['30days', '50days', \"55days\", \"40days\", \"60days\", \"35days\", \"\", \"50days\"],\n",
    "    'Discount':[1000, 2300, 1000, 1200, 2500, 1300, 1400, 1600]\n",
    "})\n",
    "\n",
    "row_labels = ['r0', 'r1', 'r2', 'r3', 'r4', 'r5', 'r6', 'r7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b945337-e437-4f92-827b-13586e8b64eb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(technologies, index=row_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3fecadc-bda7-430e-ab42-2e19bcdd2d06",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Courses      Fee Duration  Discount\nr0    Spark  22000.0   30days      1000\nr1  PySpark  25000.0   50days      2300\nr2   Hadoop  23000.0   55days      1000\nr3   Python  24000.0   40days      1200\nr4   Pandas      NaN   60days      2500\nr5     None  25000.0   35days      1300\nr6    Spark  25000.0               1400\nr7   Python  22000.0   50days      1600\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7404141a-b9e0-4e05-8d7e-ef7bca10f325",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "\n",
    "## DataFrame properties\n",
    "\n",
    "---\n",
    "\n",
    "<table><thead><tr><th>Method/Property</th><th><strong>Result</strong></th><th><strong>Description</strong></th></tr></thead><tbody><tr><td><code>df.shape</code></td><td>(8, 4)</td><td><a href=\"https://sparkbyexamples.com/pyspark/pyspark-dataframe-shape/\">Returns a shape of the pandas DataFrame (number of rows and columns)</a> as a tuple. Number of rows and columns</td></tr><tr><td><code>df.size</code></td><td>32</td><td>Returns number of cells. It would be rows * columns.</td></tr><tr><td><code>df.empty</code></td><td>False</td><td>Return boolean. True when DF is empty.</td></tr><tr><td><code>df.columns</code></td><td>Index([‘Courses’, ‘Fee’, ‘Duration’, ‘Discount’], dtype=’object’)</td><td>Returns all column names as Series</td></tr><tr><td><code>df.columns.values</code></td><td>[‘Courses’ ‘Fee’ ‘Duration’ ‘Discount’]</td><td><a href=\"https://sparkbyexamples.com/pandas/pandas-get-columns-list-from-dataframe-header/\">Returns column names from the header as a list in pandas.</a></td></tr><tr><td><code>df.index</code></td><td>Index([‘r0’, ‘r1’, ‘r2’, ‘r3’, ‘r4’, ‘r5’, ‘r6’, ‘r7′], dtype=’object’)</td><td>Returns <a href=\"https://sparkbyexamples.com/pandas/pandas-index-explained-with-examples/\">Index of DataFrame</a></td></tr><tr><td><code>df.index.values</code></td><td>[‘r0’ ‘r1’ ‘r2’ ‘r3’ ‘r4’ ‘r5’ ‘r6’ ‘r7’]</td><td>Returns Index as List.</td></tr><tr><td><code>df.dtypes</code></td><td>Courses object<br>Fee float64<br>Duration object<br>Discount int64<br>dtype: object</td><td>Returns Data types of columns</td></tr><tr><td><code>df['Fee']</code><br><code>df[['Fee','Duration']]</code></td><td>r0 22000.0<br>r1 25000.0<br>r2 23000.0<br>r3 24000.0<br>r4 NaN<br>r5 25000.0<br>r6 25000.0<br>r7 22000.0<br>Name: Fee, dtype: float64</td><td><a href=\"https://sparkbyexamples.com/pandas/pandas-select-dataframe-columns-by-label-or-index/\">Pandas Select Columns </a><a href=\"https://sparkbyexamples.com/pandas/pandas-select-columns-by-name-or-index\">by</a><a href=\"https://sparkbyexamples.com/pandas/pandas-select-dataframe-columns-by-label-or-index/\"> Name</a>.<br>Also, use to <a href=\"https://sparkbyexamples.com/pandas/pandas-select-dataframe-columns-by-label-or-index/\">select multiple columns</a></td></tr><tr><td><code>df2=df[df['Fee'] == 22000]</code></td><td>Courses Fee Duration Discount<br>r0 Spark 22000.0 30day 1000<br>r7 Python 22000.0 50days 1600</td><td><a href=\"https://sparkbyexamples.com/pandas/pandas-filter-rows-from-dataframe-query/\">Filter </a><a href=\"https://sparkbyexamples.com/pandas/pandas-dataframe-filter/\">DataFrame</a></td></tr><tr><td><code>df2=df[6:]</code></td><td>Courses Fee Duration Discount<br>r6 Spark 25000.0 30day 1400<br>r7 Python 22000.0 50days 1600</td><td><a href=\"https://sparkbyexamples.com/pandas/pandas-select-rows-by-index/\">Select Dataframe Rows by Index</a><br>Select’s Row from 6th Index</td></tr><tr><td><code>df['Duration'][3]</code><br><code>df[\"Duration\"].values[3]</code></td><td>40days</td><td><a href=\"https://sparkbyexamples.com/pandas/pandas-get-cell-value-from-dataframe/\">Get cell value (row x column) of DataFrame</a></td></tr><tr><td><code>df['Fee'] = df['Fee'] - 500</code><br><code>df['Fee']</code></td><td>r0 21500.0<br>r1 24500.0<br>r2 22500.0<br>r3 23500.0<br>r4 NaN<br>r5 24500.0<br>r6 24500.0<br>r7 21500.0</td><td>Update DataFrame Column<br>Substract 500 from ‘Fee’ Column</td></tr><tr><td>df[‘new_column’] = ”</td><td></td><td><a href=\"https://sparkbyexamples.com/pandas/pandas-add-an-empty-column-to-dataframe/\">Add new column with empty values</a></td></tr></tbody></table>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Pandas DataFrame Tutorial – Basic Operations",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
