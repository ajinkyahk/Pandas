{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff32512b-456b-4908-b102-abbc2467e11e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Pandas Series Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8f3059a-c066-4a19-a851-c3b250af638e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##What is Pandas Series\n",
    "\n",
    "---\n",
    "\n",
    "**pandas Series is a one-dimensional array that is capable of storing various data types (integer, string, float, python objects, etc.). We can easily convert the list, tuple, and dictionary into Series using the Series() method. In pandas Series, the row labels of Series are called the index. The Series can have only one column. A List, NumPy Array, Dict can be turned into a pandas Series.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82da5824-f456-4c4e-9b2d-6b95629d6cb2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Pandas Series vs DataFrame?Pandas Series vs DataFrame?\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "- As I explained above, pandas Series is a one-dimensional labeled array of the same data type whereas DataFrame is a 2-dimensional labeled data structure with columns of potentially different types. \n",
    "\n",
    "- In a DataFrame, each column of data is represented as a pandas Series.\n",
    "\n",
    "- DataFrame column can have a name/label but, Series cannot have a column name.\n",
    "\n",
    "- DataFrame can also be converted to Series and single or multiple Series can be converted to a DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58117079-7a1e-4a0c-a09a-9f4e3117884e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Pandas.series() Constructor\n",
    "\n",
    "---\n",
    "\n",
    "**Below is the syntax of pandas Series Constructor, which is used to create Pandas Series objects.**\n",
    "\n",
    "\n",
    "#### Pandas Series Constructor Syntax\n",
    "##Pandas.series(data,index,dtype,copy)\n",
    "\n",
    "\n",
    "- data: The data contains ndarray, list, constants.\n",
    "\n",
    "- Index: The index must be unique and hashable. np.arrange(n) if no index is passed.\n",
    "\n",
    "- dtype: dtype is also a data type.\n",
    "\n",
    "- copy: It is used to copy the data. The data contains ndarray, list, constants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cec9887d-8266-4ad6-9c2d-cf2e4a3351f6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Create pandas Series\n",
    "\n",
    "**pandas Series can be created in multiple ways, From array, list, dict, and from existing DataFrame.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b5b7e6d-69f9-472d-9e52-5b99a1f66d82",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##1 Create Series using array\n",
    "\n",
    "**Before creating a Series, first, we have to import the NumPy module and use array() function in the program. If the data is ndarray, then the passed index should be in the same length, if the index is not passed the default value is range(n).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8be0e9d9-b8b7-46b6-85b3-a70b3eb99d5e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61fe42d6-8eaa-408d-a57c-0c972b378c2f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    python\n1       php\n2      java\ndtype: object\n"
     ]
    }
   ],
   "source": [
    "# Create Series from array\n",
    "\n",
    "data = np.array(['python', 'php', 'java'])\n",
    "series = pd.Series(data)\n",
    "print(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d197414-f882-4490-8147-dbf3226c858f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Yields below output. Notice that the column doesn’t have a name. And Series also adds an incremental sequence number as Index (first column) by default.**\n",
    "\n",
    "\n",
    "# Output\n",
    "\n",
    "0    python\n",
    "\n",
    "1       php\n",
    "\n",
    "2      java\n",
    "\n",
    "dtype: object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7f55248-46be-46c8-9e52-fbd1ae0b42ca",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Now, let’s see how to create a pandas DataFrame with a custom Index. To do so, will use index param which takes a list of index values. Make sure the index list matches the data size.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f898507c-fb41-4757-9f2b-50fb6ccdb972",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1    python\nr2       php\nr3      java\ndtype: object\n"
     ]
    }
   ],
   "source": [
    "# Create pandas DataFrame with custom index\n",
    "s2 = pd.Series(data=data, index=['r1', 'r2', 'r3'])\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22792bf9-b9b1-4ac5-985e-f9c356cea377",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##2 Create Series using Dict\n",
    "\n",
    "---\n",
    "\n",
    "**A Dict can be used as input. Keys from Dict are used as Index and values are used as a column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfc378d0-9fd0-4227-b466-5af5088397e4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Courses     pandas\nFee          20000\nDuration    30days\ndtype: object\n"
     ]
    }
   ],
   "source": [
    "# Create a Dict from a input\n",
    "\n",
    "data = {'Courses':'pandas', 'Fee':20000, 'Duration':'30days'}\n",
    "s2 = pd.Series(data=data)\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f27a774-b7ec-4303-9891-3661cbba15e7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Now let’s see how to ignore Index from Dict and add the Index while creating a Series with Dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "063aaf06-4d75-4a48-a131-32fde4b6b806",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Courses             pandas\nCourses_Fees         20000\nCourses_Duration    30days\ndtype: object\n"
     ]
    }
   ],
   "source": [
    "# To See index from Dict and add index while creating a Series.\n",
    "data = {'Courses':\"pandas\", 'Fees':20000, 'Daration':\"30days\"}\n",
    "s2 = pd.Series(data.values(), index=['Courses', 'Courses_Fees', 'Courses_Duration'])\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87895f1c-f6bc-4607-a420-f6a21d43abff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Courses            pandas\nCourse_Fee            NaN\nCourse_Duration       NaN\ndtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# To See index from Dict and add index while creating a Series.\n",
    "data = {'Courses' :\"pandas\", 'Fees' : 20000, 'Duration' : \"30days\"}\n",
    "s2 = pd.Series(data, index=['Courses','Course_Fee','Course_Duration'])\n",
    "print (s2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5c874dd-3905-4bf2-a7c1-d59c1e63c064",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##3 Create Series using List\n",
    "\n",
    "**Below is an example of creating DataFrame from List.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a3598ce-ea94-4166-8972-b52826835e02",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1    python\nr2       php\nr3      java\ndtype: object\n"
     ]
    }
   ],
   "source": [
    "# Creating DataFrame from List\n",
    "data = ['python', 'php', 'java']\n",
    "s2 = pd.Series(data=data, index=['r1', 'r2', 'r3'])\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4734046-548e-4636-aaad-a97f8f52fe99",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##4 Create Empty Series\n",
    "\n",
    "**Sometimes you would require to create an empty Series. you can do so by using its empty constructor.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bdfaa98-518b-4478-a9bb-64670348b0f1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: float64)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<command-2048033984171043>:3: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n  s = pd.Series()\n"
     ]
    }
   ],
   "source": [
    "# Create empty Series\n",
    "\n",
    "s = pd.Series()\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94db2375-3f76-415f-8de0-0528ad36bad3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Convert a Series into a DataFrame?\n",
    "\n",
    "---\n",
    "\n",
    "**To convert Series into DataFrame, you can use pandas.concat(), pandas.merge(), DataFrame.join(). Below I have explained using concat() function. For others, please refer to pandas combine two Series to DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99ed9a99-0e51-4c87-88de-43eac822a29b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   courses   fees\n0    Spark  22000\n1  PySpark  25000\n2   Hadoop  23000\n"
     ]
    }
   ],
   "source": [
    "# Convert series to dataframe\n",
    "courses = pd.Series(['Spark', 'PySpark', 'Hadoop'], name='courses')\n",
    "fees = pd.Series([22000, 25000, 23000], name='fees')\n",
    "df = pd.concat([courses, fees], axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6606702-93b4-4d73-bfed-6c8b1dcfeb3d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Convert pandas DataFrame to Series?\n",
    "\n",
    "1. Single DataFrame column into a Series (from a single-column DataFrame)\n",
    "\n",
    "2. Specific DataFrame column into a Series (from a multi-column DataFrame)\n",
    "\n",
    "3. Single row in the DataFrame into a Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f5876f2-f91f-4300-8f33-a0eab1cb7e99",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##1 Convert a single DataFrame column into a series:\n",
    "\n",
    "\n",
    "**Let’s create a DataFrame with a single column. By using DataFrame.squeeze() to convert the DataFrame into a Series:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6eab7e36-07c6-4f48-b4aa-e6d2c8221078",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Python\n1       PHP\n2      Java\nName: Courses, dtype: object\n<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame with single column\n",
    "\n",
    "data = ['Python', 'PHP', 'Java']\n",
    "df = pd.DataFrame(data, columns=['Courses'])\n",
    "my_series = df.squeeze()\n",
    "print(my_series)\n",
    "print(type(my_series))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5d7b168-1e94-4b35-b8cf-ef2d4b21cc21",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##2. Convert a specific DataFrame column into a series:\n",
    "\n",
    "\n",
    "**If you have a DataFrame with multiple columns, and you’d like to convert a specific column into a series.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a549688e-ad6b-4616-a6f5-3e8fc25b49c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses Duration    Fee\n0    Spark  30 days  20000\n1  PySpark  40 days  25000\n2   Python  50 days  26000\n<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame with multiple columns\n",
    "\n",
    "data = {'Courses': ['Spark', 'PySpark', 'Python'],\n",
    "        'Duration':['30 days', '40 days', '50 days'],\n",
    "        'Fee':[20000, 25000, 26000]\n",
    "        }\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Courses', 'Duration', 'Fee'])\n",
    "print(df)\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d93a1ad-2a8b-4d70-b6f5-c61b4561f6a6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Let’s convert the Fee column into a Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f25a678-887c-4b1e-9d42-6dbda5fb5766",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    20000\n1    25000\n2    26000\nName: Fee, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Pandas DataFrame column to series\n",
    "my_series = df['Fee'].squeeze()\n",
    "print(my_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dfb2ad4d-aeca-4377-98b2-2020db078902",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##3 Convert DataFrame Row into a Series\n",
    "\n",
    "--- \n",
    "\n",
    "**Above, we have seen converting DataFrame columns into Series, here, I will explain converting rows into Series.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff53a009-3177-407b-aeea-5e93713e5c73",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Courses      Python\nDuration    50 days\nFee           26000\nName: 2, dtype: object\n<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# Convert DataFrame row to series\n",
    "\n",
    "my_series = df.iloc[2].squeeze()\n",
    "print(my_series)\n",
    "print(type(my_series))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e365a898-1b67-4f63-9600-e2c86c8bf6e8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Merge DataFrame and Series?\n",
    "\n",
    "1. Construct a dataframe from the series.\n",
    "\n",
    "2. After that merge with the dataframe.\n",
    "\n",
    "3. Specify the data as the values, multiply them by the length, set the columns to the index and set params for left_index and set the right_index to True.\n",
    "\n",
    "\n",
    "\n",
    "#### Syntax for merge with the DataFrame.\n",
    "\n",
    "**df.merge(pd.DataFrame(data = [s.values] * len(s), columns = s.index), left_index=True, right_index=True)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a19389f-0d83-4f45-8c7c-0caac98e6ec6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Pandas Series Attributes:\n",
    "\n",
    "<table><tbody><tr><td>T</td><td>Return the transpose, which is by definition self.</td></tr><tr><td>array</td><td>The ExtensionArray of the data backing this Series or Index.</td></tr><tr><td>at</td><td>Access a single value for a row/column label pair.</td></tr><tr><td>attrs</td><td>Dictionary of global attributes of this dataset.</td></tr><tr><td>axes</td><td>Return a list of the row axis labels.</td></tr><tr><td>dtype</td><td>Return the dtype object of the underlying data.</td></tr><tr><td>dtypes</td><td>Return the dtype object of the underlying data.</td></tr><tr><td>flags</td><td>Get the properties associated with this pandas object.</td></tr><tr><td>hasnas</td><td>Return if I have any nans; enables various perf speedups.</td></tr><tr><td>iat</td><td>Access a single value for a row/column pair by integer position.</td></tr><tr><td>iloc</td><td>Purely integer-location based indexing for selection by position.</td></tr><tr><td>index</td><td>The index (axis labels) of the Series.</td></tr><tr><td>is_monotonic</td><td>Return boolean if values in the object are monotonic_increasing.</td></tr><tr><td>is_monotonic_decreasing</td><td>Return boolean if values in the object are monotonic_decreasing.</td></tr><tr><td>is_monotonic_increasing</td><td>Alias for is_monotonic.</td></tr><tr><td>is_unique</td><td>Return boolean if values in the object are unique.</td></tr><tr><td>loc</td><td>Access a group of rows and columns by label(s) or a boolean array.</td></tr><tr><td>name</td><td>Return the name of the Series.</td></tr><tr><td>nbytes</td><td>Return the number of bytes in the underlying data.</td></tr><tr><td>ndim</td><td>Number of dimensions of the underlying data, by definition 1.</td></tr><tr><td>shape</td><td>Return a tuple of the shape of the underlying data.</td></tr><tr><td>size</td><td>Return the number of elements in the underlying data.</td></tr><tr><td>values</td><td>Return Series as ndarray or ndarray-like depending on the dtype.</td></tr></tbody></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "30fbb8c5-6384-4975-90b8-ef5722362dbf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Pandas Series Methods:\n",
    "\n",
    "<table><tbody><tr><td>abs()</td><td>Return a Series/DataFrame with absolute numeric value of each element.</td></tr><tr><td>add(other[,&nbsp;level,&nbsp;fill_value,&nbsp;axis])</td><td>Return Addition of series and other, element-wise (binary operator&nbsp;add).</td></tr><tr><td>add_prefix(prefix)</td><td>Prefix labels with string&nbsp;prefix.</td></tr><tr><td>add_suffix(suffix)</td><td>Suffix labels with string&nbsp;suffix.</td></tr><tr><td>agg([func,&nbsp;axis])</td><td>Aggregate using one or more operations over the specified axis.</td></tr><tr><td>aggregate([func,&nbsp;axis])</td><td>Aggregate using one or more operations over the specified axis.</td></tr><tr><td>align(other[,&nbsp;join,&nbsp;axis,&nbsp;level,&nbsp;copy,&nbsp;…])</td><td>Align two objects on their axes with the specified join method.</td></tr><tr><td>all([axis,&nbsp;bool_only,&nbsp;skipna,&nbsp;level])</td><td>Return whether all elements are True, potentially over an axis.</td></tr><tr><td>any([axis,&nbsp;bool_only,&nbsp;skipna,&nbsp;level])</td><td>Return whether any element is True, potentially over an axis.</td></tr><tr><td>append(to_append[,&nbsp;ignore_index,&nbsp;…])</td><td>Concatenate two or more Series.</td></tr><tr><td>apply(func[,&nbsp;convert_dtype,&nbsp;args])</td><td>Invoke function on values of Series.</td></tr><tr><td>argmax([axis,&nbsp;skipna])</td><td>Return int position of the largest value in the Series.</td></tr><tr><td>argmin([axis,&nbsp;skipna])</td><td>Return int position of the smallest value in the Series.</td></tr><tr><td>argsort([axis,&nbsp;kind,&nbsp;order])</td><td>Return the integer indices that would sort the Series values.</td></tr><tr><td>asfreq(freq[,&nbsp;method,&nbsp;how,&nbsp;normalize,&nbsp;…])</td><td>Convert time series to specified frequency.</td></tr><tr><td>asof(where[,&nbsp;subset])</td><td>Return the last row(s) without any NaNs before&nbsp;where.</td></tr><tr><td>astype(dtype[,&nbsp;copy,&nbsp;errors])</td><td>Cast a pandas object to a specified dtype&nbsp;.</td></tr><tr><td>at_time(time[,&nbsp;asof,&nbsp;axis])</td><td>Select values at particular time of day (e.g., 9:30AM).</td></tr><tr><td>autocorr([lag])</td><td>Compute the lag-N autocorrelation.</td></tr><tr><td>backfill([axis,&nbsp;inplace,&nbsp;limit,&nbsp;downcast])</td><td>Synonym for&nbsp;DataFrame.fillna()&nbsp;with&nbsp;method=”bfill”.</td></tr><tr><td>between(left,&nbsp;right[,&nbsp;inclusive])</td><td>Return boolean Series equivalent to left &lt;= series &lt;= right.</td></tr><tr><td>between_(start_time,&nbsp;end_time[,&nbsp;…])</td><td>Select values between particular times of the day (e.g., 9:00-9:30 AM).<br><br></td></tr></tbody></table>\n",
    "\n",
    "\n",
    "**Continue..**\n",
    "\n",
    "\n",
    "<table><tbody><tr><td>bfill([axis,&nbsp;inplace,&nbsp;limit,&nbsp;downcast])</td><td>Synonym for&nbsp;DataFrame.fillna() with method=”bfill”&nbsp;.</td></tr><tr><td>bool()</td><td>Return the bool of a single element Series or DataFrame.</td></tr><tr><td>cat</td><td>alias of&nbsp;pandas.core.arrays.categorical.categoricalAccessor</td></tr><tr><td>clip([lower,&nbsp;upper,&nbsp;axis,&nbsp;inplace])</td><td>Trim values at input threshold(s).</td></tr><tr><td>combine(other,&nbsp;func[,&nbsp;fill_value])</td><td>Combine the Series with a Series or scalar according to&nbsp;func.</td></tr><tr><td>combine_first(other)</td><td>Update null elements with value in the same location in ‘other’.</td></tr><tr><td>compare(other[,&nbsp;align_axis,&nbsp;keep_shape,&nbsp;…])</td><td>Compare to another Series and show the differences.</td></tr><tr><td>convert([infer_objects,&nbsp;…])</td><td>Convert columns to best possible dtypes using dtypes supporting&nbsp;pd.NA.</td></tr><tr><td>copy([deep])</td><td>Make a copy of this object’s indices and data.</td></tr><tr><td>corr(other[,&nbsp;method,&nbsp;min_periods])</td><td>Compute correlation with&nbsp;other&nbsp;Series, excluding missing values.</td></tr><tr><td>count([level])</td><td>Return number of non-NA/null observations in the Series.</td></tr><tr><td>cov(other[,&nbsp;min_periods,&nbsp;ddof])</td><td>Compute covariance with Series, excluding missing values.</td></tr><tr><td>cummax([axis,&nbsp;skipna])</td><td>Return cumulative maximum over a DataFrame or Series axis.</td></tr><tr><td>cummin([axis,&nbsp;skipna])</td><td>Return cumulative minimum over a DataFrame or Series axis.</td></tr><tr><td>cumprod([axis,&nbsp;skipna])</td><td>Return cumulative product over a DataFrame or Series axis.</td></tr><tr><td>cumsum([axis,&nbsp;skipna])</td><td>Return cumulative sum over a DataFrame or Series axis.</td></tr><tr><td>describe([percentiles,&nbsp;include,&nbsp;exclude,&nbsp;…])</td><td>Generate descriptive statistics.</td></tr><tr><td>diff([periods])</td><td>First discrete difference of element.</td></tr><tr><td>div(other[,&nbsp;level,&nbsp;fill_value,&nbsp;axis])</td><td>Return Floating division of series and other, element-wise (binary operator&nbsp;truediv).</td></tr><tr><td>divide(other[,&nbsp;level,&nbsp;fill_value,&nbsp;axis])</td><td>Return Floating division of series and other, element-wise (binary operator&nbsp;truediv).</td></tr><tr><td>divmod(other[,&nbsp;level,&nbsp;fill_value,&nbsp;axis])</td><td>Return Integer division and modulo of series and other, element-wise (binary operator&nbsp;divmod).</td></tr><tr><td>dot(other)</td><td>Compute the dot product between the Series and the columns of other.</td></tr><tr><td>drop([labels,&nbsp;axis,&nbsp;index,&nbsp;columns,&nbsp;level,&nbsp;…])</td><td>Return Series with specified index labels removed.</td></tr><tr><td>drop_duplicate([keep,&nbsp;inplace])</td><td>Return Series with duplicate values removed.</td></tr><tr><td>droplevel(level[,&nbsp;axis])</td><td>Return Series/DataFrame with requested index / column level(s) removed.</td></tr><tr><td>dropna([axis,&nbsp;inplace,&nbsp;how])</td><td>Return a new Series with missing values removed.</td></tr><tr><td>dt</td><td>alias of&nbsp;pandas.core.indexes.accessors.CombinedDatetimelikeproperties.</td></tr><tr><td>duplicated([keep])</td><td>Indicate duplicate Series values.</td></tr><tr><td>eq(other[,&nbsp;level,&nbsp;fill_value,&nbsp;axis])</td><td>Return Equal to of series and other, element-wise (binary operator&nbsp;eq).</td></tr><tr><td>equals(other)</td><td>Test whether two objects contain the same elements.</td></tr><tr><td>ewm([com,&nbsp;span,&nbsp;halflife,&nbsp;alpha,&nbsp;…])</td><td>Provide exponential weighted (EW) functions.</td></tr><tr><td>expanding([min_periods,&nbsp;center,&nbsp;axis,&nbsp;method])</td><td>Provide expanding transformations.</td></tr><tr><td>explode([ignore_index])</td><td>Transform each element of a list-like to a row.</td></tr><tr><td>factorize([sort,&nbsp;na_sentinel])</td><td>Encode the object as an enumerated type or categorical variable.</td></tr><tr><td>ffill([axis,&nbsp;inplace,&nbsp;limit,&nbsp;downcast])</td><td>Synonym for&nbsp;DataFrame.fillna()with&nbsp;method=ffill().</td></tr><tr><td>fillna([value,&nbsp;method,&nbsp;axis,&nbsp;inplace,&nbsp;…])</td><td>Fill NA/NaN values using the specified method.</td></tr><tr><td>filter([items,&nbsp;like,&nbsp;regex,&nbsp;axis])</td><td>Subset the dataframe rows or columns according to the specified index labels.</td></tr><tr><td>first(offset)</td><td>Select initial periods of time series data based on a date offset.</td></tr><tr><td>first_valid_other()</td><td>Return index for first non-NA value or None, if no NA value is found.</td></tr></tbody></table>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Pandas Series Introduction",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
