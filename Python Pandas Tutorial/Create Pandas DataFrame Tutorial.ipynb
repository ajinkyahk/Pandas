{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b143f58e-f41f-41cd-8fed-d51cc71f2940",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Create Pandas DataFrame Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ff2c50e-9ba1-4d42-ad09-2ccf22085de5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "334bee47-c2ca-42a9-a90b-1859795ff0cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0      1       2\n0   Spark  20000  30days\n1  pandas  25000  40days\n"
     ]
    }
   ],
   "source": [
    "technologies = [[\"Spark\", 20000, \"30days\"],\n",
    "               [\"pandas\", 25000, \"40days\"]]\n",
    "\n",
    "df = pd.DataFrame(technologies)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c02d0945-ca03-4936-9b82-d93d2377821c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Since we have not given index and column labels, DataFrame by default assigns incremental sequence numbers as labels to both rows and columns.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "676cb9ac-a1a1-4f8c-a3d5-96776a461b77",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Column names with sequence numbers don’t make sense as it’s hard to identify what data holds on each column hence, it is always best practice to provide column names that identify the data it holds. Use column param and index param to provide column & custom index respectively to the DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a746eef-e13f-4133-b664-ccddb02b70bb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Courses    Fee Duration\na   Spark  20000   30days\nb  pandas  25000   40days\n"
     ]
    }
   ],
   "source": [
    "# Add Column & Row Labels to the DataFrame\n",
    "column_names = [\"Courses\", \"Fee\", \"Duration\"]\n",
    "row_label = [\"a\", \"b\"]\n",
    "df = pd.DataFrame(technologies, index=row_label ,columns=column_names)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1762e759-c975-4a43-91d6-ef7f053758d8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##By default, pandas identify the data types from the data and assign’s to the DataFrame. df.dtypes returns the data type of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56e3232a-cfd5-4264-b75c-a73f53d30215",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[4]: Courses     object\nFee          int64\nDuration    object\ndtype: object"
     ]
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11390e76-6f24-4e84-b192-d0a84b1231ad",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##You can also assign custom data types to columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b18f49b7-1f9a-49bc-b4f1-24bf0499b5cb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# set custom types to DataFrame\n",
    "types = {'Courses':str, 'Fee':float, 'Duration':str}\n",
    "df = df.astype(types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0b07915-55a2-4c10-9049-abec14d6873f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[6]: Courses      object\nFee         float64\nDuration     object\ndtype: object"
     ]
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4109575d-33ba-4afc-a94b-d98f1158dab5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create DataFrame from Dictionary\n",
    "\n",
    "technologies = {\n",
    "    'Courses': [\"Spark\", \"PySpark\", \"Hadoop\"],\n",
    "    'Fee': [20000, 25000, 26000],\n",
    "    'Duration':[\"30days\", \"40days\", \"35days\"],\n",
    "    'Discount':[1000, 2300, 1500]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(technologies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27523c8c-b200-4bcf-b845-e16bf757a988",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Courses</th>\n",
       "      <th>Fee</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spark</td>\n",
       "      <td>20000</td>\n",
       "      <td>30days</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PySpark</td>\n",
       "      <td>25000</td>\n",
       "      <td>40days</td>\n",
       "      <td>2300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hadoop</td>\n",
       "      <td>26000</td>\n",
       "      <td>35days</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Courses</th>\n      <th>Fee</th>\n      <th>Duration</th>\n      <th>Discount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Spark</td>\n      <td>20000</td>\n      <td>30days</td>\n      <td>1000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>PySpark</td>\n      <td>25000</td>\n      <td>40days</td>\n      <td>2300</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hadoop</td>\n      <td>26000</td>\n      <td>35days</td>\n      <td>1500</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f3ab87f-1867-478f-a4f0-7754635bf389",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Create DataFrame with Index\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**By default, DataFrame add’s a numeric index starting from zero. It can be changed with a custom index while creating a DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10102ab9-8eb6-4eac-b04f-31543dd8d51d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Duration\nr1   Spark  20000   30days\nr2  Pandas  25000   40days\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create DataFrame with Index.\n",
    "technologies = {\n",
    "    'Courses':[\"Spark\",\"Pandas\"],\n",
    "    'Fee' :[20000,25000],\n",
    "    'Duration':['30days','40days']\n",
    "              }\n",
    "index_label=[\"r1\",\"r2\"]\n",
    "\n",
    "df = pd.DataFrame(technologies, index=index_label)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b48aee6-6d70-4d6a-a0b3-96bb9950746c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Creating Dataframe from list of dicts object\n",
    "\n",
    "\n",
    "**Sometimes we get data in JSON string (similar dict), you can convert it to DataFrame as shown below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "220a3a4e-d0cf-40d2-9359-ce2ce9b6a4fd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Courses    Fee Duration\n0   Spark  20000   30days\n1  Pandas  25000   40days\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Creates DataFrame from list of dict\n",
    "technologies = [{'Courses':'Spark', 'Fee': 20000, 'Duration':'30days'},\n",
    "        {'Courses':'Pandas', 'Fee': 25000, 'Duration': '40days'}]\n",
    "\n",
    "df = pd.DataFrame(technologies)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88102fb7-1707-4d0b-a98d-e7cbf368acad",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Creating DataFrame From Series\n",
    "\n",
    "---\n",
    "\n",
    "**By using concat() method you can create Dataframe from multiple Series. This takes several params, for the scenario we use list that takes series to combine and axis=1 to specify merge series as columns instead of rows.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ed41aa6-32d1-4a59-97c5-567ede8e5d9e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0      1       2\n0   Spark  20000  30days\n1  Pandas  25000  40days\n"
     ]
    }
   ],
   "source": [
    "# Create pandas Series\n",
    "courses = pd.Series([\"Spark\",\"Pandas\"])\n",
    "fees = pd.Series([20000,25000])\n",
    "duration = pd.Series(['30days','40days'])\n",
    "\n",
    "# Create DataFrame from series objects.\n",
    "df = pd.concat([courses, fees, duration], axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eee841f6-3455-4b20-afdf-a17da4ec26e1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Add Column Labels\n",
    "\n",
    "---\n",
    "\n",
    "**As you see above, by default concat() method doesn’t add column labels. You can do so as below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbdbf128-27c2-4306-b77c-4f98d57fd7b8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses  Courses_Fee Courses_duraion\nr1   Spark        20000          30days\nr2  Pandas        25000          40days\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assign Index to Series\n",
    "index_labels = ['r1', 'r2']\n",
    "courses.index = index_labels\n",
    "fees.index = index_labels\n",
    "duration.index = index_labels\n",
    "\n",
    "# Concat Series by Changing Names\n",
    "df = pd.concat({'Courses':courses,\n",
    "               'Courses_Fee':fees,\n",
    "               'Courses_duraion':duration}, axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e78a0a5d-ace5-4276-95db-7e6f90fa0c9a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Creating DataFrame using zip() function\n",
    "\n",
    "---\n",
    "\n",
    "**Multiple lists can be merged using zip() method and the output is used to create a DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df00551e-a702-468f-acae-552712846476",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Courses    Fee Duration\n0   Spark  20000   30days\n1  Pandas  25000   40days\n"
     ]
    }
   ],
   "source": [
    "# Create Lists\n",
    "Courses = ['Spark', 'Pandas']\n",
    "Fee = [20000, 25000]\n",
    "Duration = ['30days', '40days']\n",
    "\n",
    "#Merge lists by using zip()\n",
    "tuple_list = list(zip(Courses, Fee, Duration))\n",
    "df = pd.DataFrame(tuple_list, columns=['Courses', 'Fee', 'Duration'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54832fec-86ea-41bc-b026-22edf1e80c3c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Create an empty DataFrame in pandas\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Sometimes you would need to create an empty pandas DataFrame with or without columns. This would be required in many cases, below is one example.**\n",
    "\n",
    "**While working with files, sometimes we may not receive a file for processing, however, we still need to create a DataFrame manually with the same column names we expect. If we don’t create with the same columns, our operations/transformations (like union’s) on DataFrame fail as we refer to the columns that may not be present.**\n",
    "\n",
    "**To handle situations similar to these, we always need to create a DataFrame with the expected columns, which means the same column names and datatypes regardless of the file exists or empty file processing.**\n",
    "\n",
    "**To handle situations similar to these, we always need to create a DataFrame with the expected columns, which means the same column names and datatypes regardless of the file exists or empty file processing.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c791375e-abe1-4a11-a0d6-1d99ccf7fd6f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\nColumns: []\nIndex: []\n"
     ]
    }
   ],
   "source": [
    "# Create Empty DataFrame\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "536e3999-33d6-4b2b-9501-b400a48f8076",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##To create an empty DataFrame with just column names but no data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22cf13d9-ab3a-4cb1-8055-3662d7bec767",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\nColumns: [Courses, Fee, Duration]\nIndex: []\n"
     ]
    }
   ],
   "source": [
    "# Create Empty DataFraem with Column Labels\n",
    "df = pd.DataFrame(columns=['Courses', 'Fee', 'Duration'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b2763afb-8ed5-4b12-a122-0efb61acc6c3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Create From Another DataFrame\n",
    "\n",
    "**you can also copy a DataFrame from another DataFrame using copy() method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d06207c3-d380-4afc-a21b-a42ed0950306",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\nColumns: [Courses, Fee, Duration]\nIndex: []\n"
     ]
    }
   ],
   "source": [
    "# Copy Dataframe to another\n",
    "df2 = df.copy()\n",
    "print(df2)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Create Pandas DataFrame Tutorial",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
